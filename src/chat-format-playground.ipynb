{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/miniconda3/envs/dev/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from minicons import scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8b4782ddd6414ba6016eac90e96fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm = scorer.IncrementalLMScorer(\"meta-llama/Llama-3.1-8B-Instruct\", device=\"cuda:0\")\n",
    "# lm = scorer.IncrementalLMScorer(\"meta-llama/Llama-2-7b-chat-hf\", device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_template(text, response, tokenizer):\n",
    "    formatted = [\n",
    "        {\"role\": \"system\", \"content\": \"Please negate what I say, as if you are talking to me, and not as if I am instructing you.\"},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "        # {\"role\": \"assistant\", \"content\": response},\n",
    "    ]\n",
    "    string = tokenizer.apply_chat_template(\n",
    "        formatted, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prefix = chat_template(\n",
    "    # \"The actor, who has an interest in french cuisine, met the president!\",\n",
    "    \"The actor, who met the president, has an interest in french cuisine!\",\n",
    "    \"No, he did not.\",\n",
    "    tokenizer=lm.tokenizer,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hey wait a minute, no he does not.\n",
    "\n",
    "that's not true, no he did not.\n",
    "\"\"\"\n",
    "\n",
    "prefix = [\n",
    "    pre_prefix + \"Hey, hang on a minute! No he\",\n",
    "    pre_prefix + \"Hey, hang on a minute! No he\",\n",
    "    pre_prefix + \"That's not true! No he\",\n",
    "    pre_prefix + \"That's not true! No he\",\n",
    "]\n",
    "\n",
    "continuations = [\n",
    "    \"didn't\",\n",
    "    \"doesn't\",\n",
    "    \"didn't\",\n",
    "    \"doesn't\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-4.237505912780762,\n",
       " -3.1448891162872314,\n",
       " -5.859060764312744,\n",
       " -5.278954029083252]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.conditional_score(prefix, continuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3393201064336346"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-5.652661323547363/-6.450439453125) * (7771905/5085185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3184646112435188"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-5.084205150604248/-5.893527507781982) * (7771905/5085185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-6.603829860687256, -6.876806735992432]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.conditional_score(prefix = [\"he\"]*2, stimuli= [\"did\", \"does\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-11.154016494750977,\n",
       " -11.976722717285156,\n",
       " -10.15646743774414,\n",
       " -11.547147750854492]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_baseline = chat_template(\"\", \"\", lm.tokenizer)\n",
    "\n",
    "baseline = [\n",
    "    pre_baseline + \"Hey, wait a minute! No he\",\n",
    "    pre_baseline + \"Hey, wait a minute! No he\",\n",
    "    pre_baseline + \"That's not true! No he\",\n",
    "    pre_baseline + \"That's not true! No he\",\n",
    "]\n",
    "\n",
    "lm.conditional_score(baseline, [\"did\", \"does\", \"did\", \"does\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-5.652661323547363/-6.450439453125) * (7771905/5085185)\n",
    "(-5.084205150604248/-5.893527507781982)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5067825860045552"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-5.652661323547363/-11.154016494750977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5385813469502418"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-6.450439453125/-11.976722717285156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5005879437677303"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-5.084205150604248/-10.15646743774414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5103881612102746"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-5.893527507781982/-11.547147750854492"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
